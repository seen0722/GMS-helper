#!/usr/bin/env python3
"""
Cambrian LLM Gateway é€£ç·šæ¸¬è©¦è…³æœ¬
ç”¨æ–¼é©—è­‰å…§ç¶²ä¼ºæœå™¨èˆ‡ Cambrian çš„é€£ç·šæ˜¯å¦æ­£å¸¸

ä½¿ç”¨æ–¹å¼:
    pip install openai httpx
    python test_cambrian.py

æˆ–æŒ‡å®šåƒæ•¸:
    python test_cambrian.py --url https://api.cambrian.pegatroncorp.com --token YOUR_TOKEN --model "LLAMA 3.3 70B"
"""

import argparse
import sys

def main():
    parser = argparse.ArgumentParser(description="æ¸¬è©¦ Cambrian LLM é€£ç·š")
    parser.add_argument("--url", default="https://api.cambrian.pegatroncorp.com", help="Cambrian API URL")
    parser.add_argument("--token", required=True, help="API Token")
    parser.add_argument("--model", default="LLAMA 3.3 70B", help="Model name")
    parser.add_argument("--verify-ssl", action="store_true", help="å•Ÿç”¨ SSL é©—è­‰ (é è¨­é—œé–‰)")
    args = parser.parse_args()

    try:
        import httpx
        from openai import OpenAI
    except ImportError:
        print("âŒ ç¼ºå°‘ä¾è³´ï¼Œè«‹åŸ·è¡Œ: pip install openai httpx")
        sys.exit(1)

    verify_ssl = args.verify_ssl
    
    print("=" * 50)
    print("Cambrian LLM Gateway é€£ç·šæ¸¬è©¦")
    print("=" * 50)
    print(f"URL: {args.url}")
    print(f"Model: {args.model}")
    print(f"SSL é©—è­‰: {'é–‹å•Ÿ' if verify_ssl else 'é—œé–‰'}")
    print()

    # Test 1: HTTP é€£ç·š
    print("[1/3] æ¸¬è©¦ HTTP é€£ç·š...")
    try:
        headers = {
            "Authorization": f"Bearer {args.token}",
            "Accept": "application/json"
        }
        # æ ¹æ“šç”¨æˆ¶é©—è­‰æ›´æ–° endpoint: /assistant/llm_model
        # è™•ç† url çµå°¾å¯èƒ½æœ‰æˆ–æ²’æœ‰ /
        base_url = args.url.rstrip('/')
        url = f"{base_url}/assistant/llm_model"
        
        # ç‰¹æ®Šè™•ç†: å¦‚æœç”¨æˆ¶å‚³å…¥çš„ url å·²ç¶“å¸¶æœ‰ /v1ï¼Œå˜—è©¦ç§»é™¤å®ƒä»¥åŒ¹é…æ­£ç¢ºè·¯å¾‘
        if base_url.endswith("/v1"):
             url = base_url.replace("/v1", "/assistant/llm_model")

        print(f"      Target URL: {url}") # é¡¯ç¤ºå¯¦éš›æ‰“çš„ URL æ–¹ä¾¿é™¤éŒ¯
        r = httpx.get(url, headers=headers, verify=verify_ssl, timeout=10.0)
        
        if r.status_code == 200:
            print(f"      âœ… HTTP é€£ç·šæˆåŠŸ")
            data = r.json()
            # æ ¹æ“šæ–‡ä»¶æ›´æ–°: key ç‚º "llm_list"
            models = data.get('llm_list', [])
            if models:
                print(f"      å¯ç”¨æ¨¡å‹:")
                for m in models[:5]:
                    model_name = m.get('name', 'unknown') # æ–‡ä»¶æ˜¯ç”¨ "name"
                    desc = m.get('description', '')
                    print(f"        - {model_name} ({desc})")
                if len(models) > 5:
                    print(f"        ... é‚„æœ‰ {len(models) - 5} å€‹æ¨¡å‹")
            else:
                print("      âš ï¸  ç„¡æ³•å–å¾—æ¨¡å‹åˆ—è¡¨ (llm_list ç‚ºç©º)")
        elif r.status_code == 401:
            print(f"      âŒ èªè­‰å¤±æ•— (401) - è«‹æª¢æŸ¥ API Token")
            sys.exit(1)
        else:
            print(f"      âš ï¸  HTTP {r.status_code}: {r.text[:100]}")
    except httpx.ConnectError as e:
        print(f"      âŒ é€£ç·šå¤±æ•—: {e}")
        print("      è«‹æª¢æŸ¥ç¶²è·¯é€£ç·šå’Œ URL æ˜¯å¦æ­£ç¢º")
        sys.exit(1)
    except Exception as e:
        print(f"      âŒ éŒ¯èª¤: {e}")
        sys.exit(1)

    # Test 2: OpenAI Client åˆå§‹åŒ–
    print("\n[2/3] åˆå§‹åŒ– OpenAI Client...")
    try:
        http_client = httpx.Client(verify=verify_ssl)
        client = OpenAI(
            base_url=args.url,
            api_key=args.token,
            http_client=http_client
        )
        print("      âœ… Client åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"      âŒ Client åˆå§‹åŒ–å¤±æ•—: {e}")
        sys.exit(1)

    # Test 3: LLM å‘¼å« (éæ­·æ‰€æœ‰æ¨¡å‹)
    print("\n[3/3] æ¸¬è©¦ LLM å›æ‡‰ (éæ­·æ‰€æœ‰æ¨¡å‹)...")
    
    # å¾ Test 1 æ”¶é›†åˆ°çš„æ¨¡å‹åˆ—è¡¨ï¼Œå¦‚æœ Test 1 å¤±æ•—æˆ–æ²’æŠ“åˆ°ï¼Œå°±ç”¨åƒæ•¸æŒ‡å®šçš„å–®ä¸€æ¨¡å‹ç•¶ä½œ fallback
    target_models = []
    if 'models' in locals() and models:
        for m in models:
            m_name = m.get('name') # æ ¹æ“šå‰é¢ llm_list çµæ§‹
            if m_name:
                target_models.append(m_name)
    
    if not target_models:
        print(f"      âš ï¸  æœªåµæ¸¬åˆ°æ¨¡å‹åˆ—è¡¨ï¼Œä½¿ç”¨é è¨­/æŒ‡å®šæ¨¡å‹: {args.model}")
        target_models = [args.model]

    print(f"      å³å°‡æ¸¬è©¦ {len(target_models)} å€‹æ¨¡å‹: {', '.join(target_models)}")
    
    success_count = 0
    fail_count = 0

    for model_name in target_models:
        print(f"\n      ğŸ‘‰ æ¸¬è©¦æ¨¡å‹: {model_name}")
        try:
            response = client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "user", "content": "Say 'Hello' in one word only."}
                ],
                max_tokens=10,
                temperature=0
            )
            content = response.choices[0].message.content
            print(f"         âœ… æˆåŠŸ! å›æ‡‰: {content}")
            success_count += 1
        except Exception as e:
            print(f"         âŒ å¤±æ•—: {e}")
            fail_count += 1

    print("\n      " + "-"*30)
    print(f"      æ¸¬è©¦ç¸½çµ: æˆåŠŸ {success_count}, å¤±æ•— {fail_count}")
    if success_count == 0:
        sys.exit(1)

    print()
    print("=" * 50)
    print("âœ… æ‰€æœ‰æ¸¬è©¦é€šéï¼Cambrian é€£ç·šæ­£å¸¸ã€‚")
    print("=" * 50)


if __name__ == "__main__":
    main()
